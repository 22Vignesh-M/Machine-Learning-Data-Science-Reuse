{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import lightgbm as gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to stack output from genetic model, neural network, xgboost, lightbgm and randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also can use sklearn.LabelEncoder to do these\n",
    "\n",
    "def processdata(data):\n",
    "    # Sex\n",
    "    data.drop(['Ticket', 'Name'], inplace = True, axis = 1)\n",
    "    data.Sex.fillna('0', inplace = True)\n",
    "    data.loc[data.Sex != 'male', 'Sex'] = 0\n",
    "    data.loc[data.Sex == 'male', 'Sex'] = 1\n",
    "    # Cabin\n",
    "    data.Cabin.fillna('0', inplace = True)\n",
    "    data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = 1\n",
    "    data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = 2\n",
    "    data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = 3\n",
    "    data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = 4\n",
    "    data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = 5\n",
    "    data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = 6\n",
    "    data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = 7\n",
    "    data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = 8\n",
    "    # Embarked\n",
    "    data.loc[data.Embarked == 'C', 'Embarked'] = 1\n",
    "    data.loc[data.Embarked == 'Q', 'Embarked'] = 2\n",
    "    data.loc[data.Embarked == 'S', 'Embarked'] = 3\n",
    "    data.Embarked.fillna(0, inplace = True)\n",
    "    # fill negative result for NA\n",
    "    data.fillna(-1, inplace = True)\n",
    "    return data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_processed = processdata(train)\n",
    "test_processed = processdata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GeneticFunction(data):\n",
    "    return ((np.minimum( ((((0.058823499828577 + data[\"Sex\"]) - np.cos((data[\"Pclass\"] / 2.0))) * 2.0)),  ((0.885868))) * 2.0) +\n",
    "            np.maximum( ((data[\"SibSp\"] - 2.409090042114258)),  ( -(np.minimum( (data[\"Sex\"]),  (np.sin(data[\"Parch\"]))) * data[\"Pclass\"]))) +\n",
    "            (0.138462007045746 * ((np.minimum( (data[\"Sex\"]),  (((data[\"Parch\"] / 2.0) / 2.0))) * data[\"Age\"]) - data[\"Cabin\"])) +\n",
    "            np.minimum( ((np.sin((data[\"Parch\"] * ((data[\"Fare\"] - 0.720430016517639) * 2.0))) * 2.0)),  ((data[\"SibSp\"] / 2.0))) +\n",
    "            np.maximum( (np.minimum( ( -np.cos(data[\"Embarked\"])),  (0.138462007045746))),  (np.sin(((data[\"Cabin\"] - data[\"Fare\"]) * 2.0)))) +\n",
    "            -np.minimum( ((((data[\"Age\"] * data[\"Parch\"]) * data[\"Embarked\"]) + data[\"Parch\"])),  (np.sin(data[\"Pclass\"]))) +\n",
    "            np.minimum( (data[\"Sex\"]),  ((np.sin( -(data[\"Fare\"] * np.cos((data[\"Fare\"] * 1.630429983139038)))) / 2.0))) +\n",
    "            np.minimum( ((0.230145)),  (np.sin(np.minimum( (((67.0 / 2.0) * np.sin(data[\"Fare\"]))),  (0.31830988618379069))))) +\n",
    "            np.sin((np.sin(data[\"Cabin\"]) * (np.sin((12.6275)) * np.maximum( (data[\"Age\"]),  (data[\"Fare\"]))))) +\n",
    "            np.sin(((np.minimum( (data[\"Fare\"]),  ((data[\"Cabin\"] * data[\"Embarked\"]))) / 2.0) *  -data[\"Fare\"])) +\n",
    "            np.minimum( (((2.675679922103882 * data[\"SibSp\"]) * np.sin(((96) * np.sin(data[\"Cabin\"]))))),  (data[\"Parch\"])) +\n",
    "            np.sin(np.sin((np.maximum( (np.minimum( (data[\"Age\"]),  (data[\"Cabin\"]))),  ((data[\"Fare\"] * 0.31830988618379069))) * data[\"Cabin\"]))) +\n",
    "            np.maximum( (np.sin(((12.4148) * (data[\"Age\"] / 2.0)))),  (np.sin((-3.0 * data[\"Cabin\"])))) +\n",
    "            (np.minimum( (np.sin((((np.sin(((data[\"Fare\"] * 2.0) * 2.0)) * 2.0) * 2.0) * 2.0))),  (data[\"SibSp\"])) / 2.0) +\n",
    "            ((data[\"Sex\"] - data[\"SibSp\"]) * (np.cos(((data[\"Embarked\"] - 0.730768978595734) + data[\"Age\"])) / 2.0)) +\n",
    "            ((np.sin(data[\"Cabin\"]) / 2.0) - (np.cos(np.minimum( (data[\"Age\"]),  (data[\"Embarked\"]))) * np.sin(data[\"Embarked\"]))) +\n",
    "            np.minimum( (0.31830988618379069),  ((data[\"Sex\"] * (2.212120056152344 * (0.720430016517639 - np.sin((data[\"Age\"] * 2.0))))))) +\n",
    "            (np.minimum( (np.cos(data[\"Fare\"])),  (np.maximum( (np.sin(data[\"Age\"])),  (data[\"Parch\"])))) * np.cos((data[\"Fare\"] / 2.0))) +\n",
    "            np.sin((data[\"Parch\"] * np.minimum( ((data[\"Age\"] - 1.5707963267948966)),  ((np.cos((data[\"Pclass\"] * 2.0)) / 2.0))))) +\n",
    "            (data[\"Parch\"] * (np.sin(((data[\"Fare\"] * (0.623655974864960 * data[\"Age\"])) * 2.0)) / 2.0)) +\n",
    "            (0.31830988618379069 * np.cos(np.maximum( ((0.602940976619720 * data[\"Fare\"])),  ((np.sin(0.720430016517639) * data[\"Age\"]))))) +\n",
    "            (np.minimum( ((data[\"SibSp\"] / 2.0)),  (np.sin(((data[\"Pclass\"] - data[\"Fare\"]) * data[\"SibSp\"])))) * data[\"SibSp\"]) +\n",
    "            np.tanh((data[\"Sex\"] * np.sin((5.199999809265137 * np.sin((data[\"Cabin\"] * np.cos(data[\"Fare\"]))))))) +\n",
    "            (np.minimum( (data[\"Parch\"]),  (data[\"Sex\"])) * np.cos(np.maximum( ((np.cos(data[\"Parch\"]) + data[\"Age\"])),  (3.1415926535897931)))) +\n",
    "            (np.minimum( (np.tanh(((data[\"Cabin\"] / 2.0) + data[\"Parch\"]))),  ((data[\"Sex\"] + np.cos(data[\"Age\"])))) / 2.0) +\n",
    "            (np.sin((np.sin(data[\"Sex\"]) * (np.sin((data[\"Age\"] * data[\"Pclass\"])) * data[\"Pclass\"]))) / 2.0) +\n",
    "            (data[\"Sex\"] * (np.cos(((data[\"Sex\"] + data[\"Fare\"]) * ((8.48635) * (63)))) / 2.0)) +\n",
    "            np.minimum( (data[\"Sex\"]),  ((np.cos((data[\"Age\"] * np.tanh(np.sin(np.cos(data[\"Fare\"]))))) / 2.0))) +\n",
    "            (np.tanh(np.tanh( -np.cos((np.maximum( (np.cos(data[\"Fare\"])),  (0.094339601695538)) * data[\"Age\"])))) / 2.0) +\n",
    "            (np.tanh(np.cos((np.cos(data[\"Age\"]) + (data[\"Age\"] + np.minimum( (data[\"Fare\"]),  (data[\"Age\"])))))) / 2.0) +\n",
    "            (np.tanh(np.cos((data[\"Age\"] * ((-2.0 + np.sin(data[\"SibSp\"])) + data[\"Fare\"])))) / 2.0) +\n",
    "            (np.minimum( (((281) - data[\"Fare\"])),  (np.sin((np.maximum( ((176)),  (data[\"Fare\"])) * data[\"SibSp\"])))) * 2.0) +\n",
    "            np.sin(((np.maximum( (data[\"Embarked\"]),  (data[\"Age\"])) * 2.0) * (((785) * 3.1415926535897931) * data[\"Age\"]))) +\n",
    "            np.minimum( (data[\"Sex\"]),  (np.sin( -(np.minimum( ((data[\"Cabin\"] / 2.0)),  (data[\"SibSp\"])) * (data[\"Fare\"] / 2.0))))) +\n",
    "            np.sin(np.sin((data[\"Cabin\"] * (data[\"Embarked\"] + (np.tanh( -data[\"Age\"]) + data[\"Fare\"]))))) +\n",
    "            (np.cos(np.cos(data[\"Fare\"])) * (np.sin((data[\"Embarked\"] - ((734) * data[\"Fare\"]))) / 2.0)) +\n",
    "            ((np.minimum( (data[\"SibSp\"]),  (np.cos(data[\"Fare\"]))) * np.cos(data[\"SibSp\"])) * np.sin((data[\"Age\"] / 2.0))) +\n",
    "            (np.sin((np.sin((data[\"SibSp\"] * np.cos((data[\"Fare\"] * 2.0)))) + (data[\"Cabin\"] * 2.0))) / 2.0) +\n",
    "            (((data[\"Sex\"] * data[\"SibSp\"]) * np.sin(np.sin( -(data[\"Fare\"] * data[\"Cabin\"])))) * 2.0) +\n",
    "            (np.sin((data[\"SibSp\"] * ((((5.428569793701172 + 67.0) * 2.0) / 2.0) * data[\"Age\"]))) / 2.0) +\n",
    "            (data[\"Pclass\"] * (np.sin(((data[\"Embarked\"] * data[\"Cabin\"]) * (data[\"Age\"] - (1.07241)))) / 2.0)) +\n",
    "            (np.cos((((( -data[\"SibSp\"] + data[\"Age\"]) + data[\"Parch\"]) * data[\"Embarked\"]) / 2.0)) / 2.0) +\n",
    "            (0.31830988618379069 * np.sin(((data[\"Age\"] * ((data[\"Embarked\"] * np.sin(data[\"Fare\"])) * 2.0)) * 2.0))) +\n",
    "            ((np.minimum( ((data[\"Age\"] * 0.058823499828577)),  (data[\"Sex\"])) - 0.63661977236758138) * np.tanh(np.sin(data[\"Pclass\"]))) +\n",
    "            -np.minimum( ((np.cos(((727) * ((data[\"Fare\"] + data[\"Parch\"]) * 2.0))) / 2.0)),  (data[\"Fare\"])) +\n",
    "            (np.minimum( (np.cos(data[\"Fare\"])),  (data[\"SibSp\"])) * np.minimum( (np.sin(data[\"Parch\"])),  (np.cos((data[\"Embarked\"] * 2.0))))) +\n",
    "            (np.minimum( (((data[\"Fare\"] / 2.0) - 2.675679922103882)),  (0.138462007045746)) * np.sin((1.5707963267948966 * data[\"Age\"]))) +\n",
    "            np.minimum( ((0.0821533)),  (((np.sin(data[\"Fare\"]) + data[\"Embarked\"]) - np.cos((data[\"Age\"] * (9.89287)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Outputs(data):\n",
    "    return np.round(1.-(1./(1.+np.exp(-data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93041526374859707"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Outputs(GeneticFunction(train_processed)) == train_processed.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93% from genetic programming is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  \\\n",
       "0          1.0       0.0     3.0  1.0  22.0    1.0    0.0   7.2500    0.0   \n",
       "1          2.0       1.0     1.0  0.0  38.0    1.0    0.0  71.2833    3.0   \n",
       "2          3.0       1.0     3.0  0.0  26.0    0.0    0.0   7.9250    0.0   \n",
       "3          4.0       1.0     1.0  0.0  35.0    1.0    0.0  53.1000    3.0   \n",
       "4          5.0       0.0     3.0  1.0  35.0    0.0    0.0   8.0500    0.0   \n",
       "\n",
       "   Embarked  \n",
       "0       3.0  \n",
       "1       1.0  \n",
       "2       3.0  \n",
       "3       3.0  \n",
       "4       3.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_processed.shape)\n",
    "train_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, 8])\n",
    "Y = tf.placeholder(\"float\", [None, 2])\n",
    "layer1 = tf.Variable(tf.random_normal([8, 256]))\n",
    "layer2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "layer3 = tf.Variable(tf.random_normal([256, 128]))\n",
    "layer4 = tf.Variable(tf.random_normal([128, 2]))\n",
    "bias1 = tf.Variable(tf.random_normal([256], stddev = 0.1))\n",
    "bias2 = tf.Variable(tf.random_normal([256], stddev = 0.1))\n",
    "bias3 = tf.Variable(tf.random_normal([128], stddev = 0.1))\n",
    "bias4 = tf.Variable(tf.random_normal([2], stddev = 0.1))\n",
    "hidden1 = tf.nn.sigmoid(tf.matmul(X, layer1) + bias1)\n",
    "hidden2 = tf.nn.sigmoid(tf.matmul(hidden1, layer2) + bias2)\n",
    "hidden3 = tf.nn.sigmoid(tf.matmul(hidden2, layer3) + bias3)\n",
    "hidden4 = tf.matmul(hidden3, layer4) + bias4\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = Y, logits = hidden4))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "correct_pred = tf.equal(tf.argmax(hidden4, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 99 , avg loss: 0.317624767734 , avg acc: 0.872727272185\n",
      "epoch: 199 , avg loss: 0.280657385391 , avg acc: 0.893181815743\n",
      "epoch: 299 , avg loss: 0.254832656377 , avg acc: 0.895454543558\n",
      "epoch: 399 , avg loss: 0.240672140636 , avg acc: 0.901136364449\n",
      "epoch: 499 , avg loss: 0.225772197104 , avg acc: 0.910227270289\n",
      "epoch: 599 , avg loss: 0.214031565426 , avg acc: 0.910227270289\n",
      "epoch: 699 , avg loss: 0.2068679519 , avg acc: 0.917045451023\n",
      "epoch: 799 , avg loss: 0.196253681555 , avg acc: 0.926136360927\n",
      "epoch: 899 , avg loss: 0.188580074602 , avg acc: 0.92727272077\n",
      "epoch: 999 , avg loss: 0.183255330321 , avg acc: 0.926136358218\n",
      "epoch: 1099 , avg loss: 0.177804791199 , avg acc: 0.930681813847\n",
      "epoch: 1199 , avg loss: 0.174446646971 , avg acc: 0.931818175045\n",
      "epoch: 1299 , avg loss: 0.171144499867 , avg acc: 0.940909086303\n",
      "epoch: 1399 , avg loss: 0.175347278572 , avg acc: 0.93409090286\n",
      "epoch: 1499 , avg loss: 0.162684162232 , avg acc: 0.939772722396\n",
      "epoch: 1599 , avg loss: 0.174562242263 , avg acc: 0.932954538952\n",
      "epoch: 1699 , avg loss: 0.163085879292 , avg acc: 0.938636359843\n",
      "epoch: 1799 , avg loss: 0.155543103306 , avg acc: 0.936363630674\n",
      "epoch: 1899 , avg loss: 0.202347691679 , avg acc: 0.923863630403\n",
      "epoch: 1999 , avg loss: 0.185128070922 , avg acc: 0.923863634467\n",
      "epoch: 2099 , avg loss: 0.146408210509 , avg acc: 0.940909083594\n",
      "epoch: 2199 , avg loss: 0.200778581033 , avg acc: 0.920454541391\n",
      "epoch: 2299 , avg loss: 0.142444373489 , avg acc: 0.940909083594\n",
      "epoch: 2399 , avg loss: 0.144742918074 , avg acc: 0.945454539223\n",
      "epoch: 2499 , avg loss: 0.138463883872 , avg acc: 0.94659090313\n",
      "epoch: 2599 , avg loss: 0.135515746449 , avg acc: 0.945454540578\n",
      "epoch: 2699 , avg loss: 0.134597714313 , avg acc: 0.945454540578\n",
      "epoch: 2799 , avg loss: 0.132481446701 , avg acc: 0.948863630945\n",
      "epoch: 2899 , avg loss: 0.132481453136 , avg acc: 0.945454539223\n",
      "epoch: 2999 , avg loss: 0.133701577825 , avg acc: 0.948863628236\n",
      "epoch: 3099 , avg loss: 0.132919807114 , avg acc: 0.945454540578\n",
      "epoch: 3199 , avg loss: 0.165552622639 , avg acc: 0.940909084949\n",
      "epoch: 3299 , avg loss: 0.1267870171 , avg acc: 0.953409083865\n",
      "epoch: 3399 , avg loss: 0.141195227561 , avg acc: 0.949999994852\n",
      "epoch: 3499 , avg loss: 0.126560757191 , avg acc: 0.94886362959\n",
      "epoch: 3599 , avg loss: 0.123399597931 , avg acc: 0.957954538139\n",
      "epoch: 3699 , avg loss: 0.14117569525 , avg acc: 0.947727265683\n",
      "epoch: 3799 , avg loss: 0.122574519133 , avg acc: 0.956818174232\n",
      "epoch: 3899 , avg loss: 0.134589432104 , avg acc: 0.945454540578\n",
      "epoch: 3999 , avg loss: 0.121665507555 , avg acc: 0.956818175587\n",
      "epoch: 4099 , avg loss: 0.117656666277 , avg acc: 0.955681810325\n",
      "epoch: 4199 , avg loss: 0.135934195651 , avg acc: 0.947727267038\n",
      "epoch: 4299 , avg loss: 0.135053268168 , avg acc: 0.946590900421\n",
      "epoch: 4399 , avg loss: 0.118317436766 , avg acc: 0.955681811679\n",
      "epoch: 4499 , avg loss: 0.128913828913 , avg acc: 0.956818174232\n",
      "epoch: 4599 , avg loss: 0.112656270598 , avg acc: 0.960227264599\n",
      "epoch: 4699 , avg loss: 0.128849484259 , avg acc: 0.953409083865\n",
      "epoch: 4799 , avg loss: 0.108686150454 , avg acc: 0.961363629861\n",
      "epoch: 4899 , avg loss: 0.116861471441 , avg acc: 0.960227267309\n",
      "epoch: 4999 , avg loss: 0.128945285116 , avg acc: 0.947727265683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "array_processed = train_processed.iloc[:, 2:].values\n",
    "# f(x(ij)) = x(ij) - x min(j) / x max(j) - x min(j)\n",
    "# iterate over column if want to do manually\n",
    "normalize_train = MinMaxScaler().fit_transform(array_processed)\n",
    "\n",
    "# 5k epochs\n",
    "for i in range(5000):\n",
    "    total_loss, total_acc = 0, 0\n",
    "    # 20 per batch, we loss 11 information\n",
    "    for k in range(0, (array_processed.shape[0] // 20) * 20, 20):\n",
    "        batch_x = np.zeros((20, 8))\n",
    "        batch_x = normalize_train[k: k + 20, :]\n",
    "        batch_y = np.zeros((20, 2))\n",
    "        for n in range(20):\n",
    "            batch_y[n, int(train_processed.iloc[k + n, 1])] = 1.0\n",
    "        lost, _ = sess.run([loss, optimizer], feed_dict = {X: batch_x, Y: batch_y})\n",
    "        total_acc += sess.run(accuracy, feed_dict = {X: batch_x, Y: batch_y})\n",
    "        total_loss += lost\n",
    "    total_loss /= (array_processed.shape[0] // 20)\n",
    "    total_acc /= (array_processed.shape[0] // 20)\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print('epoch:', i, ', avg loss:', total_loss, ', avg acc:', total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95173967"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((train_processed.iloc[:, 1].shape[0], 2))\n",
    "for i in range(train_processed.iloc[:, 1].shape[0]):\n",
    "    y[i, int(train_processed.iloc[i, 1])] = 1.0\n",
    "sess.run(accuracy, feed_dict = {X: normalize_train, Y: y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.261504\n",
      "Will train until train-error hasn't improved in 100 rounds.\n",
      "[50]\ttrain-error:0.103255\n",
      "[100]\ttrain-error:0.089787\n",
      "[150]\ttrain-error:0.077441\n",
      "[200]\ttrain-error:0.069585\n",
      "[250]\ttrain-error:0.060606\n",
      "[300]\ttrain-error:0.059484\n",
      "[350]\ttrain-error:0.056117\n",
      "[400]\ttrain-error:0.050505\n",
      "[450]\ttrain-error:0.046016\n",
      "[500]\ttrain-error:0.04826\n",
      "[550]\ttrain-error:0.041526\n",
      "[600]\ttrain-error:0.042649\n",
      "[650]\ttrain-error:0.047138\n",
      "Stopping. Best iteration:\n",
      "[550]\ttrain-error:0.041526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators' : 2000,\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 2,\n",
    "    'gamma': 0.9,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic'\n",
    "}\n",
    "\n",
    "watchlist = [(xgb.DMatrix(normalize_train, train_processed.iloc[:, 1].values), 'train')]\n",
    "model = xgb.train(params, (xgb.DMatrix(normalize_train, train_processed.iloc[:, 1].values)), 1000,  watchlist, verbose_eval=50, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95510662177328842"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.around(model.predict(xgb.DMatrix(normalize_train), ntree_limit=model.best_ntree_limit+80)) == train_processed.iloc[:, 1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.95% accurate! more higher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 4,\n",
    "    'min_child_weight': 2,\n",
    "    'sub_feature': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary'\n",
    "}\n",
    "\n",
    "d_train = gbm.Dataset(normalize_train, train_processed.iloc[:, 1].values)\n",
    "watchlist = [gbm.Dataset(normalize_train, train_processed.iloc[:, 1].values)]\n",
    "clf = gbm.train(params, d_train, 1000, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96296296296296291"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.around(clf.predict(normalize_train)) == train_processed.iloc[:, 1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.96% accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0        892.0     3.0  1.0  34.5    0.0    0.0   7.8292    0.0       2.0\n",
       "1        893.0     3.0  0.0  47.0    1.0    0.0   7.0000    0.0       3.0\n",
       "2        894.0     2.0  1.0  62.0    0.0    0.0   9.6875    0.0       2.0\n",
       "3        895.0     3.0  1.0  27.0    0.0    0.0   8.6625    0.0       3.0\n",
       "4        896.0     3.0  0.0  22.0    1.0    1.0  12.2875    0.0       3.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_ga = Outputs(GeneticFunction(test_processed))\n",
    "normalize_test = MinMaxScaler().fit_transform(test_processed.iloc[:, 1:])\n",
    "output_nn = sess.run(tf.argmax(hidden4, 1), feed_dict = {X: normalize_test})\n",
    "output_xgb = np.around(model.predict(xgb.DMatrix(normalize_test), ntree_limit=model.best_ntree_limit+80))\n",
    "putput_gbm = np.around(clf.predict(normalize_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier().fit(normalize_train, train_processed.iloc[:, 1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97194163860830529"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(forest.predict(normalize_train) == train_processed.iloc[:, 1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_forest = forest.predict(normalize_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_stack = output_ga * 0.5 + output_nn * 0.3 + output_xgb * 0.1 + putput_gbm * 0.095 + output_forest * 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StackingSubmission = pd.DataFrame({ 'PassengerId': test_processed.iloc[:, 0].astype(int),\n",
    "                            'Survived': np.around(outputs_stack).astype(int)})\n",
    "StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
