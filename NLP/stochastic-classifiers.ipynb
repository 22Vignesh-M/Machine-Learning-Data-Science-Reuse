{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will to show how to use linear model stochastic gradient descent on multi-class classification/discrimination\n",
    "\n",
    "import class sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import re\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions to help us on preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear string\n",
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string]\n",
    "    string = ' '.join(string)\n",
    "    return string\n",
    "\n",
    "# because of sklean.datasets read a document as a single element\n",
    "# so we want to split based on new line\n",
    "def separate_dataset(trainset):\n",
    "    datastring = []\n",
    "    datatarget = []\n",
    "    for i in range(len(trainset.data)):\n",
    "        data_ = trainset.data[i].split('\\n')\n",
    "        # python3, if python2, just remove list()\n",
    "        data_ = list(filter(None, data_))\n",
    "        for n in range(len(data_)):\n",
    "            data_[n] = clearstring(data_[n])\n",
    "        datastring += data_\n",
    "        for n in range(len(data_)):\n",
    "            datatarget.append(trainset.target[i])\n",
    "    return datastring, datatarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included 6 classes in local/\n",
    "1. adidas (wear)\n",
    "2. apple (electronic)\n",
    "3. hungry (status)\n",
    "4. kerajaan (government related)\n",
    "5. nike (wear)\n",
    "6. pembangkang (opposition related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adidas', 'apple', 'hungry', 'kerajaan', 'nike', 'pembangkang']\n",
      "25292\n",
      "25292\n"
     ]
    }
   ],
   "source": [
    "# you can change any encoding type\n",
    "trainset = sklearn.datasets.load_files(container_path = 'local', encoding = 'UTF-8')\n",
    "trainset.data, trainset.target = separate_dataset(trainset)\n",
    "print (trainset.target_names)\n",
    "print (len(trainset.data))\n",
    "print (len(trainset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# bag-of-word\n",
    "bow = CountVectorizer().fit_transform(trainset.data)\n",
    "\n",
    "#tf-idf, must get from BOW first\n",
    "tfidf = TfidfTransformer().fit_transform(bow)\n",
    "\n",
    "#hashing, default n_features, probability cannot divide by negative\n",
    "hashing = HashingVectorizer(non_negative = True).fit_transform(trainset.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss function got {'modified_huber', 'hinge', 'log', 'squared_hinge', 'perceptron'}\n",
    "\n",
    "default is hinge, will give you classic SVM\n",
    "\n",
    "perceptron in linear loss\n",
    "\n",
    "huber and log both logistic classifier\n",
    "\n",
    "#### penalty got {'l1', 'l2'}, to prevent overfitting\n",
    "\n",
    "l1 = MAE (mean absolute error)\n",
    "\n",
    "l2 = RMSE (root mean square error)\n",
    "\n",
    "#### alpha is learning rate\n",
    "\n",
    "#### n_iter is number of epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.87131844238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.96      0.85      0.90       279\n",
      "      apple       0.99      0.82      0.90       434\n",
      "     hungry       0.99      0.89      0.94      1060\n",
      "   kerajaan       0.87      0.85      0.86      1436\n",
      "       nike       0.93      0.82      0.87       303\n",
      "pembangkang       0.77      0.91      0.83      1547\n",
      "\n",
      "avg / total       0.88      0.87      0.87      5059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(bow, trainset.target, test_size = 0.2)\n",
    "\n",
    "mod_huber = SGDClassifier(loss = 'modified_huber', \n",
    "                                  penalty = 'l2', alpha = 1e-3, \n",
    "                                  n_iter = 10).fit(train_X, train_Y)\n",
    "predicted = mod_huber.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.867958094485\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.93      0.83      0.88       306\n",
      "      apple       0.99      0.78      0.87       451\n",
      "     hungry       0.99      0.91      0.95      1043\n",
      "   kerajaan       0.86      0.85      0.86      1406\n",
      "       nike       0.97      0.77      0.86       321\n",
      "pembangkang       0.76      0.91      0.83      1532\n",
      "\n",
      "avg / total       0.88      0.87      0.87      5059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(tfidf, trainset.target, test_size = 0.2)\n",
    "\n",
    "mod_huber = SGDClassifier(loss = 'modified_huber', \n",
    "                                  penalty = 'l2', alpha = 1e-3, \n",
    "                                  n_iter = 10).fit(train_X, train_Y)\n",
    "predicted = mod_huber.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.849970349872\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.95      0.85      0.90       313\n",
      "      apple       0.98      0.77      0.87       478\n",
      "     hungry       0.99      0.90      0.95      1046\n",
      "   kerajaan       0.84      0.82      0.83      1377\n",
      "       nike       0.98      0.77      0.87       310\n",
      "pembangkang       0.73      0.88      0.80      1535\n",
      "\n",
      "avg / total       0.87      0.85      0.85      5059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(hashing, trainset.target, test_size = 0.2)\n",
    "\n",
    "mod_huber = SGDClassifier(loss = 'modified_huber', \n",
    "                                  penalty = 'l2', alpha = 1e-3, \n",
    "                                  n_iter = 10).fit(train_X, train_Y)\n",
    "predicted = mod_huber.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always BOW got the highest accuracy among other vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let we use linear model to do classifers, I will use BOW as vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.859458390986\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.94      0.83      0.88       312\n",
      "      apple       0.97      0.78      0.87       459\n",
      "     hungry       1.00      0.89      0.94      1044\n",
      "   kerajaan       0.85      0.85      0.85      1407\n",
      "       nike       0.96      0.76      0.85       313\n",
      "pembangkang       0.75      0.90      0.82      1524\n",
      "\n",
      "avg / total       0.87      0.86      0.86      5059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(bow, trainset.target, test_size = 0.2)\n",
    "\n",
    "svm = SGDClassifier(penalty = 'l2', alpha = 1e-3, n_iter = 10).fit(train_X, train_Y)\n",
    "predicted = svm.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.844040324175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.96      0.82      0.88       306\n",
      "      apple       0.97      0.80      0.88       486\n",
      "     hungry       0.99      0.88      0.93      1033\n",
      "   kerajaan       0.88      0.78      0.82      1384\n",
      "       nike       0.96      0.79      0.87       320\n",
      "pembangkang       0.70      0.91      0.79      1530\n",
      "\n",
      "avg / total       0.87      0.84      0.85      5059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(bow, trainset.target, test_size = 0.2)\n",
    "\n",
    "sq_hinge = SGDClassifier(loss = 'squared_hinge', \n",
    "                                  penalty = 'l2', alpha = 1e-3, \n",
    "                                  n_iter = 10).fit(train_X, train_Y)\n",
    "predicted = sq_hinge.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.865388416683\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.94      0.87      0.90       305\n",
      "      apple       0.96      0.82      0.89       471\n",
      "     hungry       0.96      0.90      0.93      1056\n",
      "   kerajaan       0.84      0.85      0.84      1395\n",
      "       nike       0.95      0.82      0.88       333\n",
      "pembangkang       0.78      0.88      0.83      1499\n",
      "\n",
      "avg / total       0.87      0.87      0.87      5059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(bow, trainset.target, test_size = 0.2)\n",
    "\n",
    "perceptron = SGDClassifier(loss = 'perceptron', \n",
    "                                  penalty = 'l2', alpha = 1e-3, \n",
    "                                  n_iter = 10).fit(train_X, train_Y)\n",
    "predicted = perceptron.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how to get probability of our output?\n",
    "\n",
    "Only applicable if your loss = {'log', 'modified_huber'} because both are logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy validation set:  0.872306779996\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     adidas       0.93      0.85      0.88       312\n",
      "      apple       0.98      0.82      0.89       442\n",
      "     hungry       0.98      0.90      0.94      1040\n",
      "   kerajaan       0.87      0.86      0.86      1384\n",
      "       nike       0.96      0.78      0.86       346\n",
      "pembangkang       0.78      0.91      0.84      1535\n",
      "\n",
      "avg / total       0.88      0.87      0.87      5059\n",
      "\n",
      "['Najib emulating Trump in using tweets to spread his politics of fear hatred and lies', 'Ministers mooted exit may be linked to Sabah snap polls']\n",
      "[5, 5]\n",
      "[[ 0.          0.          0.          0.04299312  0.          0.95700688]\n",
      " [ 0.          0.03000789  0.          0.03931672  0.01663784  0.91403755]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(bow, trainset.target, test_size = 0.2)\n",
    "\n",
    "mod_huber = SGDClassifier(loss = 'modified_huber', \n",
    "                                  penalty = 'l2', alpha = 1e-3, \n",
    "                                  n_iter = 10).fit(train_X, train_Y)\n",
    "predicted = mod_huber.predict(test_X)\n",
    "print('accuracy validation set: ', np.mean(predicted == test_Y))\n",
    "\n",
    "# print scores\n",
    "print(metrics.classification_report(test_Y, predicted, target_names = trainset.target_names))\n",
    "\n",
    "# get probability for first 2 sentence in our dataset\n",
    "print(trainset.data[:2])\n",
    "print(trainset.target[:2])\n",
    "print(mod_huber.predict_proba(bow[:2, :]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
